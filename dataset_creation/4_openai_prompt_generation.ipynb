{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:14:08.889053Z",
     "start_time": "2025-05-22T13:14:08.747186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from openai import OpenAI\n",
    "import uuid\n",
    "\n",
    "PATH_PROMPTS = \"../dataset/Dataset40k/prompts\"\n",
    "PATH_SPOTIFY_YOUTUBE_CSV = \"../dataset/Dataset40k/spotify_with_youtube_clean.csv\"\n",
    "PATH_SAVE_FINAL_CSV = \"../dataset/Dataset40k/spotify_with_youtube_and_prompts.csv\"\n",
    "\n",
    "assert os.path.exists(PATH_PROMPTS), f\"Received bad path `{PATH_PROMPTS}`\"\n",
    "assert os.path.exists(PATH_SPOTIFY_YOUTUBE_CSV), f\"Received bad path `{PATH_SPOTIFY_YOUTUBE_CSV}`\"\n",
    "assert not os.path.exists(PATH_SAVE_FINAL_CSV), f\"`{PATH_SAVE_FINAL_CSV}` already exists.\"\n",
    "\n",
    "__OPENAI_API_KEY = <ENTER_YOUR_OWN_OPENAI_API_KEY_HERE>\n",
    "openai_api = OpenAI(api_key=__OPENAI_API_KEY)"
   ],
   "id": "1057939de6228a16",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Create ChatGPT Prompts\n",
    "\n",
    "Prompt generation is fairly time-consuming, so be patience, it’s slow.\n",
    "<br><br>\n",
    "I wrote a simple script to run 10 processes in parallel, it works fine with openAI, so perhaps do that.\n",
    "\n",
    "```bash\n",
    "python .\\parallel_chatgpt_prompt_creation.py --start_index 0  \n",
    "...  \n",
    "python .\\parallel_chatgpt_prompt_creation.py --start_index 1  \n",
    "python .\\parallel_chatgpt_prompt_creation.py --start_index 9  \n",
    "```  \n",
    "\n"
   ],
   "id": "4d168ed5a8978246"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#######################################################\n",
    "# Helpers\n",
    "#######################################################\n",
    "\n",
    "GPT_INSTRUCTIONS = \"\"\"\n",
    "INSTRUCTIONS:\n",
    "I'll send you song metadata (from Spotify) like this:\n",
    "{\n",
    "    track_id: int,\n",
    "    artists: [Artist Name(s)],\n",
    "    track_name: Track Name,\n",
    "danceability: float, # 0.0 (least danceable) to 1.0 (most danceable)\n",
    "energy: float, # 0.0 (least energetic) to 1.0 (most energetic)\n",
    "key: int, 0=C, 1=C#/Db, etc.\n",
    "mode: int, 1=Major, 0=Minor\n",
    "speechiness: float, #0.0 (least spoken words) to 1.0 (most spoken)\n",
    "liveness: float, #0.0 (studio recording) to 1.0 (live performance)\n",
    "valence: float, #0.0 (sad/negative) to 1.0 (happy/positive)\n",
    "track_genre: Genre\n",
    "}\n",
    "\n",
    "Based on this, generate 10 different, concise, 2-sentence visual image prompts that reflect the song's mood, emotion, and atmosphere. Be extremely creative with the styling—go crazy with different artistic approaches and aesthetics.\n",
    "\n",
    "Respond simply with 10 lines, one for each prompt, and nothing else!\n",
    "\"\"\"\n",
    "\n",
    "def get_prompt(api_instance, row, gpt_instructions, model=\"gpt-4o-mini\", expected_prompt_count:int=3):\n",
    "    # Setup\n",
    "    EXPECTED_COLUMNS = [\"artists\", \"track_name\", \"danceability\", \"energy\", \"key\", \"mode\", \"speechiness\", \"liveness\", \"valence\", \"track_genre\"]\n",
    "    assert all([(c in list(row.index)) for c in EXPECTED_COLUMNS])\n",
    "    metadata_prompt = str(dict(row[EXPECTED_COLUMNS]))\n",
    "\n",
    "    # Get prompt from chatgpt\n",
    "    response = api_instance.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": gpt_instructions},\n",
    "            {\"role\": \"user\", \"content\": metadata_prompt},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Format output\n",
    "    response_string = response.choices[0].message.content\n",
    "    splits = response_string.split(\"\\n\")\n",
    "    splits = [s for s in splits if (len(s) > expected_prompt_count)]\n",
    "    prompts = [prompt.strip() for prompt in splits]\n",
    "    assert len(splits) == expected_prompt_count, splits\n",
    "    return response, prompts\n",
    "\n",
    "#######################################################\n",
    "# Prepare dataframe\n",
    "#######################################################\n",
    "\n",
    "# Load csv and remove already \n",
    "df = pd.read_csv(PATH_SPOTIFY_YOUTUBE_CSV)\n",
    "expected_columns = [\"track_id\", \"artists\", \"track_name\", \"danceability\", \"energy\", \"key\", \"mode\", \"speechiness\", \"liveness\", \"valence\", \"track_genre\"]\n",
    "renamer = {\n",
    "    'spotify_artists':'artists',\n",
    "    'spotify_track_name':'track_name',\n",
    "    'spotify_danceability': 'danceability',\n",
    "    'spotify_energy':'energy',\n",
    "    'spotify_key':'key',\n",
    "    'spotify_mode':'mode',\n",
    "    'spotify_speechiness':'speechiness',\n",
    "    'spotify_liveness':'liveness',\n",
    "    'spotify_valence':'valence',\n",
    "    'spotify_genre':'track_genre',\n",
    "}\n",
    "\n",
    "#######################################################\n",
    "# Get prompts from ChatGPT\n",
    "#######################################################\n",
    "\n",
    "for row_index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    # Setup\n",
    "    row = row.rename(index=renamer)\n",
    "    track_id = row[\"spotify_track_id\"]\n",
    "    json_path = f\"{PATH_PROMPTS}/{track_id}.json\"\n",
    "    if os.path.exists(json_path):\n",
    "        continue\n",
    "\n",
    "    # Auto generate the prompt --> prompt = gpt(spotify_data, some_instructions)\n",
    "    random_seed = str(uuid.uuid4())\n",
    "    randomly_seeded_instructions = f\"RANDOM SEED:\\n{random_seed}\\n{GPT_INSTRUCTIONS}\"\n",
    "    try:\n",
    "        response, prompts = get_prompt(\n",
    "            api_instance=openai_api, \n",
    "            row=row, \n",
    "            gpt_instructions=randomly_seeded_instructions, \n",
    "            expected_prompt_count=10\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(row_index, \": \", e)\n",
    "        continue\n",
    "\n",
    "    # Clean prompt\n",
    "    response = dict(response)\n",
    "    expected_keys_from_chatgpt = ['id', 'choices', 'created', 'model', 'object', 'service_tier', 'system_fingerprint', 'usage']\n",
    "    assert list(response.keys()) == expected_keys_from_chatgpt\n",
    "    assert len(response[\"choices\"]) == 1\n",
    "    choices = response[\"choices\"][0]\n",
    "    choices = dict(choices)\n",
    "    choices[\"message\"] = dict(choices[\"message\"])\n",
    "    response[\"choices\"] = choices\n",
    "    response[\"usage\"] = dict(response[\"usage\"])\n",
    "    response[\"clean_prompts\"] = response[\"choices\"][\"message\"][\"content\"].split(\"\\n\\n\")\n",
    "\n",
    "    # Save json file\n",
    "    with open(json_path, 'w') as json_file:\n",
    "        json.dump(dict(response), json_file, indent=4)\n",
    "    del response"
   ],
   "id": "7ff56cf11679d717",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Add prompts to dataframe",
   "id": "841d4aeef090a9a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:14:16.254143Z",
     "start_time": "2025-05-22T13:14:15.707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(PATH_SPOTIFY_YOUTUBE_CSV)\n",
    "assert len(df[\"spotify_track_id\"].unique()) == len(df)\n",
    "prompt_paths = glob(f\"{PATH_PROMPTS}/*\")\n",
    "prompt_track_ids = [os.path.basename(p)[:-5] for p in prompt_paths]\n",
    "as_track_id_match = df[\"path_audio_full\"].apply(os.path.basename).apply(lambda x: x.split(\".\")[0]).isin(prompt_track_ids)\n",
    "print(f\"Rows with no match: {sum(~as_track_id_match)}/{len(df)}\") \n",
    "df = df[as_track_id_match]\n",
    "print(f\"Rows remaining: {len(df)}\")"
   ],
   "id": "dd267d8689bf35ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with no match: 1/37453\n",
      "Rows remaining: 37452\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:14:20.616683Z",
     "start_time": "2025-05-22T13:14:16.589622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load prompts\n",
    "openai_prompts = []\n",
    "failed = []\n",
    "for track_id in df[\"spotify_track_id\"]:\n",
    "    json_path = f\"{PATH_PROMPTS}/{track_id}.json\"\n",
    "    with open(json_path, \"r\") as f:\n",
    "        prompts = json.load(f)[\"clean_prompts\"]\n",
    "    if len(prompts) != 10:\n",
    "        prompts = []\n",
    "        failed.append(track_id)\n",
    "    elif not all([prompts[i].startswith(f\"{i+1}. \") for i in range(10)]):\n",
    "        prompts = []\n",
    "        failed.append(track_id)\n",
    "    else:\n",
    "        prompts = [re.sub(rf\"^{i+1}\\. \", \"\", prompt) for i, prompt in enumerate(prompts)]\n",
    "    openai_prompts.append(prompts)\n",
    "\n",
    "# Remove bad prompts\n",
    "df[\"openai_prompts\"] = openai_prompts\n",
    "bad_prompts = df[\"openai_prompts\"].apply(len) == 0\n",
    "print(f\"Rows with at least one bad prompt: {sum(bad_prompts)}/{len(df)}\")\n",
    "assert df[bad_prompts][\"spotify_track_id\"].isin(failed).all()\n",
    "assert bad_prompts.sum() == len(failed)\n",
    "df = df[~bad_prompts]\n",
    "df.to_csv(PATH_SAVE_FINAL_CSV, index=False)\n",
    "print(f\"Rows remaining: {len(df)}\")"
   ],
   "id": "cc8089a6a627db1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with at least one bad prompt: 682/37452\n",
      "Rows remaining: 36770\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
