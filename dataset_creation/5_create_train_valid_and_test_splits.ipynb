{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:29:00.809992Z",
     "start_time": "2025-05-22T13:29:00.804563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ast import literal_eval\n",
    "\n",
    "PATH_DATASET_CSV = \"../dataset/Dataset40k/spotify_with_youtube_and_prompts.csv\"\n",
    "assert os.path.exists(PATH_DATASET_CSV), f\"Received bad path `{PATH_DATASET_CSV}`\"\n",
    "\n",
    "PATH_SAVE_FINAL_CSV = \"../dataset/Dataset40k/dataset.csv\"\n",
    "assert not os.path.exists(PATH_SAVE_FINAL_CSV), f\"`{PATH_SAVE_FINAL_CSV}` already exists.\""
   ],
   "id": "30aee31638c93cf7",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Remove rows that have more than one genre\n",
    "NOTE: The way I have design the train/valid split require single genre songs.<br>\n",
    "You could do something more intelligently here, but there are so few cases that I didn't bother."
   ],
   "id": "6c19c1df90e668c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:29:03.540674Z",
     "start_time": "2025-05-22T13:29:02.500911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(PATH_DATASET_CSV)\n",
    "df[\"spotify_genre\"] = df[\"spotify_genre\"].apply(literal_eval)\n",
    "assert all(df[\"spotify_genre\"].apply(len) >= 1)\n",
    "has_more_than_one_genre = df[\"spotify_genre\"].apply(len) != 1\n",
    "print(f\"Rows with 2+ genres: {sum(has_more_than_one_genre)}/{len(df)}\")\n",
    "df = df[~has_more_than_one_genre]\n",
    "df[\"spotify_genre\"] = df[\"spotify_genre\"].apply(lambda x: x[0])\n",
    "print(f\"Rows remaining: {len(df)}\")"
   ],
   "id": "dccb624b4618dcf7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with 2+ genres: 307/36770\n",
      "Rows remaining: 36463\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Splits",
   "id": "b5ab996794736302"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:29:14.143199Z",
     "start_time": "2025-05-22T13:29:12.597334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Decide on the number of bins for numerical variables\n",
    "n_bins = 4\n",
    "min_group_size = 2\n",
    "\n",
    "# Removing rows with 5+ artists\n",
    "artist_count = df[\"spotify_artists\"].apply(literal_eval).apply(len)\n",
    "print(\"Tracks with a more than 5 artists: \", sum(artist_count > 5))\n",
    "df = df[artist_count <= 5]\n",
    "\n",
    "# Create bins for 'spotify_valence' and 'spotify_energy'\n",
    "df['valence_bin'] = pd.cut(df['spotify_valence'], bins=n_bins, labels=False)\n",
    "df['energy_bin'] = pd.cut(df['spotify_energy'], bins=n_bins, labels=False)\n",
    "\n",
    "# Combine 'spotify_genre', 'valence_bin', and 'energy_bin' to create a stratification key\n",
    "df['stratify_key'] = (\n",
    "        df['spotify_genre'].astype(str) + '_' +\n",
    "        df['valence_bin'].astype(str) + '_' +\n",
    "        df['energy_bin'].astype(str)\n",
    ")\n",
    "\n",
    "# Combine rare combinations into a single category\n",
    "strat_counts = df['stratify_key'].value_counts()\n",
    "rare_stratify_keys = list(strat_counts[strat_counts < min_group_size].keys())\n",
    "df.loc[df['stratify_key'].isin(rare_stratify_keys), 'stratify_key'] = \"rare\"\n",
    "strat_counts = df['stratify_key'].value_counts()\n",
    "assert df['stratify_key'].value_counts().min() >= min_group_size\n",
    "print(strat_counts)\n",
    "\n",
    "# Stratified train-valid split\n",
    "train_track_ids, valid_track_ids = train_test_split(\n",
    "    df[\"spotify_track_id\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['stratify_key']\n",
    ")\n",
    "assert len(set(train_track_ids.values)) + len(set(valid_track_ids.values)) == len(df) == len(set(df[\"spotify_track_id\"].unique()))\n",
    "assert not any(train_track_ids.isin(valid_track_ids))\n",
    "assert not any(valid_track_ids.isin(train_track_ids))\n",
    "\n",
    "# These are the 32 IDs used for experiment 2. \n",
    "# They will become the test dataset.\n",
    "test_track_ids = [\n",
    "    '5vjLSffimiIP26QG5WcN2K', \n",
    "    '2QjOHCTQ1Jl3zawyYOpxh6', \n",
    "    '60a0Rd6pjrkxjPbaKzXjfq', \n",
    "    '0yc6Gst2xkRu0eMLeRMGCX', \n",
    "    '5ygDXis42ncn6kYG14lEVG', \n",
    "    '3WMj8moIAXJhHsyLaqIIHI', \n",
    "    '5YbPxJwPfrj7uswNwoF1pJ', \n",
    "    '3XucsgiwXb8KPn9Csf9Zmu', \n",
    "    '2grjqo0Frpf2okIBiifQKs', \n",
    "    '3WBRfkOozHEsG0hbrBzwlm', \n",
    "    '1WCEAGGRD066z2Q89ObXTq', \n",
    "    '3ZCTVFBt2Brf31RLEnCkWJ', \n",
    "    '3S7A85bAWOd6ltk6r2ANOI', \n",
    "    '1Fid2jjqsHViMX6xNH70hE', \n",
    "    '5XeFesFbtLpXzIVDNQP22n', \n",
    "    '0lP4HYLmvowOKdsQ7CVkuq', \n",
    "    '2HZLXBOnaSRhXStMLrq9fD', \n",
    "    '2tTmW7RDtMQtBk7m2rYeSw', \n",
    "    '5KTBaWu8IOczQ0sPWzZ7MY', \n",
    "    '0o9zmvc5f3EFApU52PPIyW', \n",
    "    '2gYj9lubBorOPIVWsTXugG', \n",
    "    '37ZJ0p5Jm13JPevGcx4SkF', \n",
    "    '3zb8S65LhiPPPH4vov8yV2', \n",
    "    '4h9wh7iOZ0GGn8QVp4RAOB', \n",
    "    '4LRPiXqCikLlN15c3yImP7', \n",
    "    '5itOtNx0WxtJmi1TQ3RuRd', \n",
    "    '6mFkJmJqdDVQ1REhVfGgd1', \n",
    "    '39shmbIHICJ2Wxnk1fPSdz', \n",
    "    '44AyOl4qVkzS48vBsbNXaC', \n",
    "    '7eJMfftS33KTjuF7lTsMCx', \n",
    "    '2TktkzfozZifbQhXjT6I33', \n",
    "    '4RvWPyQ5RL0ao9LPZeSouE'\n",
    "]\n",
    "\n",
    "# Assign splits\n",
    "df.loc[df[\"spotify_track_id\"].isin(train_track_ids), \"train_split\"] = \"train\"\n",
    "df.loc[df[\"spotify_track_id\"].isin(valid_track_ids), \"train_split\"] = \"valid\"\n",
    "df.loc[df[\"spotify_track_id\"].isin(test_track_ids),  \"train_split\"] = \"test\"\n",
    "renamer = {'valence_bin':'train_valence_bin', 'energy_bin':'train_energy_bin', 'stratify_key':'train_stratify_key'}\n",
    "df = df.rename(columns=renamer)\n",
    "\n",
    "# Validate that there's no data leakage between splits\n",
    "train_df = df[df['train_split'] == 'train']\n",
    "valid_df = df[df['train_split'] == 'valid']\n",
    "test_df = df[df['train_split'] == 'test']\n",
    "train_ids = set(train_df['spotify_track_id'])\n",
    "valid_ids = set(valid_df['spotify_track_id'])\n",
    "test_ids = set(test_df['spotify_track_id'])\n",
    "\n",
    "train_valid_overlap = train_ids.intersection(valid_ids)\n",
    "if train_valid_overlap: # Check for overlaps between train and validation sets\n",
    "    print(\"Data leakage detected between train and validation sets!\")\n",
    "    print(f\"Overlapping 'spotify_track_id's: {train_valid_overlap}\")\n",
    "\n",
    "train_test_overlap = train_ids.intersection(test_ids)\n",
    "if train_test_overlap: # Check for overlaps between train and test sets\n",
    "    print(\"Data leakage detected between train and test sets!\")\n",
    "    print(f\"Overlapping 'spotify_track_id's: {train_test_overlap}\")\n",
    "\n",
    "valid_test_overlap = valid_ids.intersection(test_ids)\n",
    "if valid_test_overlap: # Check for overlaps between validation and test sets\n",
    "    print(\"Data leakage detected between validation and test sets!\")\n",
    "    print(f\"Overlapping 'spotify_track_id's: {valid_test_overlap}\")\n",
    "\n",
    "total_unique_ids = set(df['spotify_track_id'])\n",
    "assigned_ids = train_ids.union(valid_ids).union(test_ids)\n",
    "if total_unique_ids != assigned_ids: # Additional validation: Ensure all 'spotify_track_id's are assigned to a split\n",
    "    missing_ids = total_unique_ids - assigned_ids\n",
    "    print(\"Some 'spotify_track_id's are not assigned to any split!\")\n",
    "    print(f\"Missing 'spotify_track_id's: {missing_ids}\")\n",
    "print(df[\"train_split\"].value_counts())\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(PATH_SAVE_FINAL_CSV, index=False)"
   ],
   "id": "fdfde0919ac7587d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks with a more than 5 artists:  121\n",
      "stratify_key\n",
      "forro_3_3          376\n",
      "salsa_3_3          241\n",
      "ambient_0_0        236\n",
      "grunge_1_3         219\n",
      "salsa_3_2          211\n",
      "                  ... \n",
      "world-music_2_0      2\n",
      "industrial_0_0       2\n",
      "piano_2_0            2\n",
      "breakbeat_3_2        2\n",
      "show-tunes_3_3       2\n",
      "Name: count, Length: 1176, dtype: int64\n",
      "train_split\n",
      "train    29053\n",
      "valid     7257\n",
      "test        32\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
